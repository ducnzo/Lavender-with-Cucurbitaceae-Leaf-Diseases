{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.applications.efficientnet import preprocess_input, EfficientNetB5, EfficientNetB4\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications import MobileNetV3Large, MobileNetV3Small\n",
    "from keras.applications.efficientnet_v2 import EfficientNetV2B0, EfficientNetV2B1, EfficientNetV2B2, EfficientNetV2B3, EfficientNetV2S, EfficientNetV2M, EfficientNetV2L\n",
    "\n",
    "# Tạo model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from keras.models import Model\n",
    "\n",
    "# Tạo và xử lý data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Hàm loss và optimizer\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Callbacks\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tabulate import tabulate\n",
    "# ROC Curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "#Checkpoint and log\n",
    "from keras.callbacks import CSVLogger\n",
    "import tempfile\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "\n",
    "#Time inference\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNetV2B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng mô hình\n",
    "num_classes = 4\n",
    "IMG_SIZE = 224\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(weights=None, include_top=True, classes=num_classes) \n",
    "predictions = base_model(inputs)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Đóng băng các lớp của mô hình base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn đến thư mục chứa dữ liệu\n",
    "data_dir = 'Data_Cucur_augmented/train'\n",
    "test_dir = 'Data_Cucur_augmented/test'\n",
    "# Thiết lập các thông số\n",
    "validation_ratio = 0.1\n",
    "\n",
    "# Sử dụng ImageDataGenerator để tạo dữ liệu và áp dụng các biến đổi\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=validation_ratio,\n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Tạo generator cho tập train và tập validation\n",
    "train_data_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Chỉ sử dụng tập huấn luyện\n",
    ")\n",
    "\n",
    "val_data_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Chỉ sử dụng tập validation\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1 / 255.0)\n",
    "test_data_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data_generator.filepaths))\n",
    "print(len(val_data_generator.filepaths))\n",
    "print(len(test_data_generator.filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save log\n",
    "class TimeTrainCSVLogger(tf.keras.callbacks.CSVLogger):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "        super().on_epoch_begin(epoch, logs)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - self.epoch_start_time\n",
    "        logs['time_per_epoch'] = epoch_duration\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        print(f\"Epoch {epoch + 1} - Training Time: {epoch_duration:.2f} seconds\")\n",
    "        \n",
    "class TrainingTimeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.start_time = time.time()\n",
    "        super().on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        end_time = time.time()\n",
    "        duration = end_time - self.start_time\n",
    "        super().on_train_end(logs)\n",
    "        hours = duration // 3600\n",
    "        minutes = (duration - (hours * 3600)) // 60\n",
    "        seconds = duration - ((hours * 3600) + (minutes * 60))\n",
    "        \n",
    "        msg = f'Total Training Time: {int(hours)} hours, {int(minutes)} minutes, {seconds:.2f} seconds'\n",
    "        print(msg)\n",
    "\n",
    "        # Ghi tổng thời gian huấn luyện vào tệp CSV\n",
    "        with open('efficientNetV2B0/log/train_logger1.csv', mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Total Training Time (seconds)'])\n",
    "            writer.writerow([duration])\n",
    "            writer.writerow(['Total Training Time (hours, minutes, seconds)'])\n",
    "            writer.writerow([hours, minutes, seconds])\n",
    "\n",
    "csv_logger = TimeTrainCSVLogger('efficientNetV2B0/log/train_logger1.csv', append=True, separator='\\t')\n",
    "\n",
    "checkpoint_filepath = \"efficientNetV2B0/checkpoint/cp1.ckpt\"\n",
    "directory_checkpoint = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    verbose=2,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer và loss function\n",
    "loss = CategoricalCrossentropy()\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics= ['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# Tính toán số bước cho tập train và tập validation\n",
    "steps_per_epoch = train_data_generator.samples // batch_size\n",
    "validation_steps = val_data_generator.samples // batch_size\n",
    "\n",
    "history = model.fit(train_data_generator,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          validation_steps= validation_steps, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=val_data_generator, \n",
    "          callbacks=[model_checkpoint_callback,csv_logger,TrainingTimeCallback()]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá mô hình trên tệp test\n",
    "test_loss, test_accuracy, test_recall, test_precision = model.evaluate(test_data_generator)\n",
    "\n",
    "print(f'Test_loss: {test_loss}')\n",
    "print(f'Test_accuracy: {test_accuracy}')\n",
    "print(f'Test_recall: {test_recall}')\n",
    "print(f'Test_precision: {test_precision}')\n",
    "\n",
    "with open('efficientNetV2B0/Test_data_metrics1.txt', 'w') as file:\n",
    "    file.write(f'Test_loss: {test_loss}\\n')\n",
    "    file.write(f'Test_accuracy: {test_accuracy}\\n')\n",
    "    file.write(f'Test_recall: {test_recall}\\n')\n",
    "    file.write(f'Test_precision: {test_precision}\\n')\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save('efficientNetV2B0/efficientnet_v2_b0_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy thông tin về độ chính xác trên tập huấn luyện và tập validation\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của accuracy\n",
    "plt.plot(range(1, epochs + 1), train_accuracy, label='Training Accuracy')\n",
    "plt.plot(range(1, epochs + 1), val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B0/accuracy_vs_epochs_v2b0.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Lấy thông tin về loss trên tập huấn luyện và tập validation\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của loss\n",
    "plt.plot(range(1, epochs + 1), train_loss, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B0/loss_vs_epochs_v2b0.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'precision' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B0/precision_vs_epochs_v2b0.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B0/recall_vs_epochs_v2b0.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B0/recall_vs_epochs_v2b0.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và lấy nhãn dự đoán\n",
    "y_pred = model.predict(test_data_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Lấy nhãn thật của tập kiểm tra\n",
    "y_true_indices = test_data_generator.classes\n",
    "\n",
    "# Lấy danh sách các lớp từ tên thư mục trong val_data_generator\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "\n",
    "# Sử dụng chỉ số thứ tự để lấy tên của các lớp từ danh sách tên lớp\n",
    "y_true_classes = [class_names[i] for i in y_true_indices]\n",
    "\n",
    "# Tính toán confusion matrix\n",
    "cm = confusion_matrix(y_true_indices, y_pred_labels)\n",
    "\n",
    "# Hiển thị confusion matrix bằng heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('efficientNetV2B0/confusion_matrix_v2b0.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Tính classification report\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "report = classification_report(y_true_indices, y_pred_labels, target_names=class_names, output_dict=True)\n",
    "\n",
    "# Tạo bảng classification report\n",
    "report_table = []\n",
    "for class_name, metrics in report.items():\n",
    "    if class_name in class_names:\n",
    "        row = [class_name, metrics['precision'], metrics['recall'], metrics['f1-score']]\n",
    "        report_table.append(row)\n",
    "\n",
    "headers = [\"Class\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "report_text = tabulate(report_table, headers, tablefmt=\"pretty\")\n",
    "# Lưu bảng classification report vào tệp văn bản\n",
    "with open('efficientNetV2B0/classification_report_v2b0.txt', 'w') as file:\n",
    "    file.write(report_text)\n",
    "\n",
    "# In bảng classification report ra màn hình\n",
    "print(report_text)\n",
    "\n",
    "# Chuyển đổi nhãn thành định dạng mã hóa one-hot\n",
    "y_test_binary = label_binarize(test_data_generator.labels, classes=range(len(class_names)))\n",
    "\n",
    "# Khởi tạo một từ điển trống để lưu FPR và TPR cho mỗi lớp\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "# Tạo một hình ảnh cho các đường ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Duyệt qua từng lớp\n",
    "for i in range(len(class_names)):\n",
    "    # Tính toán đường ROC và AUC cho lớp hiện tại\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binary[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Vẽ đường ROC cho lớp hiện tại\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve for {class_names[i]} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Cài đặt plot\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('efficientNetV2B0/ROC_curve_v2b0.png') # save before show. If not, it will save a blank image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNetV2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng mô hình\n",
    "num_classes = 4\n",
    "IMG_SIZE = 224\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(weights=None, include_top=True, classes=num_classes) \n",
    "predictions = base_model(inputs)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Đóng băng các lớp của mô hình base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save log\n",
    "class TimeTrainCSVLogger(tf.keras.callbacks.CSVLogger):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "        super().on_epoch_begin(epoch, logs)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - self.epoch_start_time\n",
    "        logs['time_per_epoch'] = epoch_duration\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        print(f\"Epoch {epoch + 1} - Training Time: {epoch_duration:.2f} seconds\")\n",
    "        \n",
    "class TrainingTimeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.start_time = time.time()\n",
    "        super().on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        end_time = time.time()\n",
    "        duration = end_time - self.start_time\n",
    "        super().on_train_end(logs)\n",
    "        hours = duration // 3600\n",
    "        minutes = (duration - (hours * 3600)) // 60\n",
    "        seconds = duration - ((hours * 3600) + (minutes * 60))\n",
    "        \n",
    "        msg = f'Total Training Time: {int(hours)} hours, {int(minutes)} minutes, {seconds:.2f} seconds'\n",
    "        print(msg)\n",
    "\n",
    "        # Ghi tổng thời gian huấn luyện vào tệp CSV\n",
    "        with open('mobileNetV2/log/train_logger2.csv', mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Total Training Time (seconds)'])\n",
    "            writer.writerow([duration])\n",
    "            writer.writerow(['Total Training Time (hours, minutes, seconds)'])\n",
    "            writer.writerow([hours, minutes, seconds])\n",
    "\n",
    "csv_logger = TimeTrainCSVLogger('mobileNetV2/log/train_logger2.csv', append=True, separator='\\t')\n",
    "\n",
    "checkpoint_filepath = \"mobileNetV2/checkpoint/cp2.ckpt\"\n",
    "directory_checkpoint = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    verbose=2,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer và loss function\n",
    "loss = CategoricalCrossentropy()\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics= ['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# Tính toán số bước cho tập train và tập validation\n",
    "steps_per_epoch = train_data_generator.samples // batch_size\n",
    "validation_steps = val_data_generator.samples // batch_size\n",
    "\n",
    "history = model.fit(train_data_generator,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          validation_steps= validation_steps, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=val_data_generator, \n",
    "          callbacks=[model_checkpoint_callback,csv_logger,TrainingTimeCallback()]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá mô hình trên tệp test\n",
    "test_loss, test_accuracy, test_recall, test_precision = model.evaluate(test_data_generator)\n",
    "\n",
    "print(f'Test_loss: {test_loss}')\n",
    "print(f'Test_accuracy: {test_accuracy}')\n",
    "print(f'Test_recall: {test_recall}')\n",
    "print(f'Test_precision: {test_precision}')\n",
    "\n",
    "with open('mobileNetV2/Test_data_metrics2.txt', 'w') as file:\n",
    "    file.write(f'Test_loss: {test_loss}\\n')\n",
    "    file.write(f'Test_accuracy: {test_accuracy}\\n')\n",
    "    file.write(f'Test_recall: {test_recall}\\n')\n",
    "    file.write(f'Test_precision: {test_precision}\\n')\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save('mobileNetV2/mobileNetV2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy thông tin về độ chính xác trên tập huấn luyện và tập validation\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của accuracy\n",
    "plt.plot(range(1, epochs + 1), train_accuracy, label='Training Accuracy')\n",
    "plt.plot(range(1, epochs + 1), val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('mobileNetV2/accuracy_vs_epochs_mobileNetV2.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Lấy thông tin về loss trên tập huấn luyện và tập validation\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của loss\n",
    "plt.plot(range(1, epochs + 1), train_loss, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('mobileNetV2/loss_vs_epochs_mobileNetV2.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'precision' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('mobileNetV2/precision_vs_epochs_mobileNetV2.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('mobileNetV2/recall_vs_epochs_mobileNetV2.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('mobileNetV2/recall_vs_epochs_mobileNetV2.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và lấy nhãn dự đoán\n",
    "y_pred = model.predict(test_data_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Lấy nhãn thật của tập kiểm tra\n",
    "y_true_indices = test_data_generator.classes\n",
    "\n",
    "# Lấy danh sách các lớp từ tên thư mục trong val_data_generator\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "\n",
    "# Sử dụng chỉ số thứ tự để lấy tên của các lớp từ danh sách tên lớp\n",
    "y_true_classes = [class_names[i] for i in y_true_indices]\n",
    "\n",
    "# Tính toán confusion matrix\n",
    "cm = confusion_matrix(y_true_indices, y_pred_labels)\n",
    "\n",
    "# Hiển thị confusion matrix bằng heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('mobileNetV2/confusion_matrix_mobileNetV2.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Tính classification report\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "report = classification_report(y_true_indices, y_pred_labels, target_names=class_names, output_dict=True)\n",
    "\n",
    "# Tạo bảng classification report\n",
    "report_table = []\n",
    "for class_name, metrics in report.items():\n",
    "    if class_name in class_names:\n",
    "        row = [class_name, metrics['precision'], metrics['recall'], metrics['f1-score']]\n",
    "        report_table.append(row)\n",
    "\n",
    "headers = [\"Class\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "report_text = tabulate(report_table, headers, tablefmt=\"pretty\")\n",
    "# Lưu bảng classification report vào tệp văn bản\n",
    "with open('mobileNetV2/classification_report_mobileNetV2.txt', 'w') as file:\n",
    "    file.write(report_text)\n",
    "\n",
    "# In bảng classification report ra màn hình\n",
    "print(report_text)\n",
    "\n",
    "# Chuyển đổi nhãn thành định dạng mã hóa one-hot\n",
    "y_test_binary = label_binarize(test_data_generator.labels, classes=range(len(class_names)))\n",
    "\n",
    "# Khởi tạo một từ điển trống để lưu FPR và TPR cho mỗi lớp\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "# Tạo một hình ảnh cho các đường ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Duyệt qua từng lớp\n",
    "for i in range(len(class_names)):\n",
    "    # Tính toán đường ROC và AUC cho lớp hiện tại\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binary[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Vẽ đường ROC cho lớp hiện tại\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve for {class_names[i]} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Cài đặt plot\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('mobileNetV2/ROC_curve_mobileNetV2.png') # save before show. If not, it will save a blank image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNetV3Large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng mô hình\n",
    "num_classes = 4\n",
    "IMG_SIZE = 224\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model = tf.keras.applications.MobileNetV3Large(weights=None, include_top=True, classes=num_classes, dropout_rate=0.2) \n",
    "predictions = base_model(inputs)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Đóng băng các lớp của mô hình base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save log\n",
    "class TimeTrainCSVLogger(tf.keras.callbacks.CSVLogger):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "        super().on_epoch_begin(epoch, logs)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - self.epoch_start_time\n",
    "        logs['time_per_epoch'] = epoch_duration\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        print(f\"Epoch {epoch + 1} - Training Time: {epoch_duration:.2f} seconds\")\n",
    "        \n",
    "class TrainingTimeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.start_time = time.time()\n",
    "        super().on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        end_time = time.time()\n",
    "        duration = end_time - self.start_time\n",
    "        super().on_train_end(logs)\n",
    "        hours = duration // 3600\n",
    "        minutes = (duration - (hours * 3600)) // 60\n",
    "        seconds = duration - ((hours * 3600) + (minutes * 60))\n",
    "        \n",
    "        msg = f'Total Training Time: {int(hours)} hours, {int(minutes)} minutes, {seconds:.2f} seconds'\n",
    "        print(msg)\n",
    "\n",
    "        # Ghi tổng thời gian huấn luyện vào tệp CSV\n",
    "        with open('mobileNetV3Large/log/train_logger3.csv', mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Total Training Time (seconds)'])\n",
    "            writer.writerow([duration])\n",
    "            writer.writerow(['Total Training Time (hours, minutes, seconds)'])\n",
    "            writer.writerow([hours, minutes, seconds])\n",
    "\n",
    "csv_logger = TimeTrainCSVLogger('mobileNetV3Large/log/train_logger3.csv', append=True, separator='\\t')\n",
    "\n",
    "checkpoint_filepath = \"mobileNetV3Large/checkpoint/cp3.ckpt\"\n",
    "directory_checkpoint = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    verbose=2,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer và loss function\n",
    "loss = CategoricalCrossentropy()\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics= ['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# Tính toán số bước cho tập train và tập validation\n",
    "steps_per_epoch = train_data_generator.samples // batch_size\n",
    "validation_steps = val_data_generator.samples // batch_size\n",
    "\n",
    "history = model.fit(train_data_generator,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          validation_steps= validation_steps, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=val_data_generator, \n",
    "          callbacks=[model_checkpoint_callback,csv_logger,TrainingTimeCallback()]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá mô hình trên tệp test\n",
    "test_loss, test_accuracy, test_recall, test_precision = model.evaluate(test_data_generator)\n",
    "\n",
    "print(f'Test_loss: {test_loss}')\n",
    "print(f'Test_accuracy: {test_accuracy}')\n",
    "print(f'Test_recall: {test_recall}')\n",
    "print(f'Test_precision: {test_precision}')\n",
    "\n",
    "with open('mobileNetV3Large/Test_data_metrics3.txt', 'w') as file:\n",
    "    file.write(f'Test_loss: {test_loss}\\n')\n",
    "    file.write(f'Test_accuracy: {test_accuracy}\\n')\n",
    "    file.write(f'Test_recall: {test_recall}\\n')\n",
    "    file.write(f'Test_precision: {test_precision}\\n')\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save('mobileNetV3Large/mobileNetV3Large_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy thông tin về độ chính xác trên tập huấn luyện và tập validation\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của accuracy\n",
    "plt.plot(range(1, epochs + 1), train_accuracy, label='Training Accuracy')\n",
    "plt.plot(range(1, epochs + 1), val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('mobileNetV3Large/accuracy_vs_epochs_mv3l.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Lấy thông tin về loss trên tập huấn luyện và tập validation\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của loss\n",
    "plt.plot(range(1, epochs + 1), train_loss, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('mobileNetV3Large/loss_vs_epochs_mv3l.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'precision' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('mobileNetV3Large/precision_vs_epochs_mv3l.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('mobileNetV3Large/recall_vs_epochs_mv3l.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('mobileNetV3Large/recall_vs_epochs_mv3l.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và lấy nhãn dự đoán\n",
    "y_pred = model.predict(test_data_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Lấy nhãn thật của tập kiểm tra\n",
    "y_true_indices = test_data_generator.classes\n",
    "\n",
    "# Lấy danh sách các lớp từ tên thư mục trong val_data_generator\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "\n",
    "# Sử dụng chỉ số thứ tự để lấy tên của các lớp từ danh sách tên lớp\n",
    "y_true_classes = [class_names[i] for i in y_true_indices]\n",
    "\n",
    "# Tính toán confusion matrix\n",
    "cm = confusion_matrix(y_true_indices, y_pred_labels)\n",
    "\n",
    "# Hiển thị confusion matrix bằng heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('mobileNetV3Large/confusion_matrix_mv3l.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Tính classification report\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "report = classification_report(y_true_indices, y_pred_labels, target_names=class_names, output_dict=True)\n",
    "\n",
    "# Tạo bảng classification report\n",
    "report_table = []\n",
    "for class_name, metrics in report.items():\n",
    "    if class_name in class_names:\n",
    "        row = [class_name, metrics['precision'], metrics['recall'], metrics['f1-score']]\n",
    "        report_table.append(row)\n",
    "\n",
    "headers = [\"Class\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "report_text = tabulate(report_table, headers, tablefmt=\"pretty\")\n",
    "# Lưu bảng classification report vào tệp văn bản\n",
    "with open('mobileNetV3Large/classification_report_mv3l.txt', 'w') as file:\n",
    "    file.write(report_text)\n",
    "\n",
    "# In bảng classification report ra màn hình\n",
    "print(report_text)\n",
    "\n",
    "# Chuyển đổi nhãn thành định dạng mã hóa one-hot\n",
    "y_test_binary = label_binarize(test_data_generator.labels, classes=range(len(class_names)))\n",
    "\n",
    "# Khởi tạo một từ điển trống để lưu FPR và TPR cho mỗi lớp\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "# Tạo một hình ảnh cho các đường ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Duyệt qua từng lớp\n",
    "for i in range(len(class_names)):\n",
    "    # Tính toán đường ROC và AUC cho lớp hiện tại\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binary[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Vẽ đường ROC cho lớp hiện tại\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve for {class_names[i]} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Cài đặt plot\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('mobileNetV3Large/ROC_curve_mv3l.png') # save before show. If not, it will save a blank image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNetV3Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng mô hình\n",
    "num_classes = 4\n",
    "IMG_SIZE = 224\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model = tf.keras.applications.MobileNetV3Small(weights=None, include_top=True, classes=num_classes, dropout_rate=0.2)\n",
    "predictions = base_model(inputs)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Đóng băng các lớp của mô hình base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save log\n",
    "class TimeTrainCSVLogger(tf.keras.callbacks.CSVLogger):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "        super().on_epoch_begin(epoch, logs)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - self.epoch_start_time\n",
    "        logs['time_per_epoch'] = epoch_duration\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        print(f\"Epoch {epoch + 1} - Training Time: {epoch_duration:.2f} seconds\")\n",
    "        \n",
    "class TrainingTimeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.start_time = time.time()\n",
    "        super().on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        end_time = time.time()\n",
    "        duration = end_time - self.start_time\n",
    "        super().on_train_end(logs)\n",
    "        hours = duration // 3600\n",
    "        minutes = (duration - (hours * 3600)) // 60\n",
    "        seconds = duration - ((hours * 3600) + (minutes * 60))\n",
    "        \n",
    "        msg = f'Total Training Time: {int(hours)} hours, {int(minutes)} minutes, {seconds:.2f} seconds'\n",
    "        print(msg)\n",
    "\n",
    "        # Ghi tổng thời gian huấn luyện vào tệp CSV\n",
    "        with open('mobileNetV3Small/log/train_logger4.csv', mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Total Training Time (seconds)'])\n",
    "            writer.writerow([duration])\n",
    "            writer.writerow(['Total Training Time (hours, minutes, seconds)'])\n",
    "            writer.writerow([hours, minutes, seconds])\n",
    "\n",
    "csv_logger = TimeTrainCSVLogger('mobileNetV3Small/log/train_logger4.csv', append=True, separator='\\t')\n",
    "\n",
    "checkpoint_filepath = \"mobileNetV3Small/checkpoint/cp4.ckpt\"\n",
    "directory_checkpoint = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    verbose=2,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer và loss function\n",
    "loss = CategoricalCrossentropy()\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics= ['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# Tính toán số bước cho tập train và tập validation\n",
    "steps_per_epoch = train_data_generator.samples // batch_size\n",
    "validation_steps = val_data_generator.samples // batch_size\n",
    "\n",
    "history = model.fit(train_data_generator,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          validation_steps= validation_steps, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=val_data_generator, \n",
    "          callbacks=[model_checkpoint_callback,csv_logger,TrainingTimeCallback()]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá mô hình trên tệp test\n",
    "test_loss, test_accuracy, test_recall, test_precision = model.evaluate(test_data_generator)\n",
    "\n",
    "print(f'Test_loss: {test_loss}')\n",
    "print(f'Test_accuracy: {test_accuracy}')\n",
    "print(f'Test_recall: {test_recall}')\n",
    "print(f'Test_precision: {test_precision}')\n",
    "\n",
    "with open('mobileNetV3Small/Test_data_metrics4.txt', 'w') as file:\n",
    "    file.write(f'Test_loss: {test_loss}\\n')\n",
    "    file.write(f'Test_accuracy: {test_accuracy}\\n')\n",
    "    file.write(f'Test_recall: {test_recall}\\n')\n",
    "    file.write(f'Test_precision: {test_precision}\\n')\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save('mobileNetV3Small/mobileNetV3Small_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy thông tin về độ chính xác trên tập huấn luyện và tập validation\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của accuracy\n",
    "plt.plot(range(1, epochs + 1), train_accuracy, label='Training Accuracy')\n",
    "plt.plot(range(1, epochs + 1), val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('mobileNetV3Small/accuracy_vs_epochs_4.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Lấy thông tin về loss trên tập huấn luyện và tập validation\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của loss\n",
    "plt.plot(range(1, epochs + 1), train_loss, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('mobileNetV3Small/loss_vs_epochs_4.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'precision' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('mobileNetV3Small/precision_vs_epochs_4.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('mobileNetV3Small/recall_vs_epochs_4.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('mobileNetV3Small/recall_vs_epochs_4.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và lấy nhãn dự đoán\n",
    "y_pred = model.predict(test_data_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Lấy nhãn thật của tập kiểm tra\n",
    "y_true_indices = test_data_generator.classes\n",
    "\n",
    "# Lấy danh sách các lớp từ tên thư mục trong val_data_generator\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "\n",
    "# Sử dụng chỉ số thứ tự để lấy tên của các lớp từ danh sách tên lớp\n",
    "y_true_classes = [class_names[i] for i in y_true_indices]\n",
    "\n",
    "# Tính toán confusion matrix\n",
    "cm = confusion_matrix(y_true_indices, y_pred_labels)\n",
    "\n",
    "# Hiển thị confusion matrix bằng heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('mobileNetV3Small/confusion_matrix_4.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Tính classification report\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "report = classification_report(y_true_indices, y_pred_labels, target_names=class_names, output_dict=True)\n",
    "\n",
    "# Tạo bảng classification report\n",
    "report_table = []\n",
    "for class_name, metrics in report.items():\n",
    "    if class_name in class_names:\n",
    "        row = [class_name, metrics['precision'], metrics['recall'], metrics['f1-score']]\n",
    "        report_table.append(row)\n",
    "\n",
    "headers = [\"Class\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "report_text = tabulate(report_table, headers, tablefmt=\"pretty\")\n",
    "# Lưu bảng classification report vào tệp văn bản\n",
    "with open('mobileNetV3Small/classification_report_4.txt', 'w') as file:\n",
    "    file.write(report_text)\n",
    "\n",
    "# In bảng classification report ra màn hình\n",
    "print(report_text)\n",
    "\n",
    "# Chuyển đổi nhãn thành định dạng mã hóa one-hot\n",
    "y_test_binary = label_binarize(test_data_generator.labels, classes=range(len(class_names)))\n",
    "\n",
    "# Khởi tạo một từ điển trống để lưu FPR và TPR cho mỗi lớp\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "# Tạo một hình ảnh cho các đường ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Duyệt qua từng lớp\n",
    "for i in range(len(class_names)):\n",
    "    # Tính toán đường ROC và AUC cho lớp hiện tại\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binary[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Vẽ đường ROC cho lớp hiện tại\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve for {class_names[i]} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Cài đặt plot\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('mobileNetV3Small/ROC_curve_4.png') # save before show. If not, it will save a blank image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNetV2M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng mô hình\n",
    "num_classes = 4\n",
    "IMG_SIZE = 480\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2M(weights=None, include_top=True, classes=num_classes) \n",
    "predictions = base_model(inputs)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Đóng băng các lớp của mô hình base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn đến thư mục chứa dữ liệu\n",
    "data_dir = 'Data_Cucur_augmented/train'\n",
    "test_dir = 'Data_Cucur_augmented/test'\n",
    "# Thiết lập các thông số\n",
    "validation_ratio = 0.1\n",
    "\n",
    "# Sử dụng ImageDataGenerator để tạo dữ liệu và áp dụng các biến đổi\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=validation_ratio,\n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Tạo generator cho tập train và tập validation\n",
    "train_data_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Chỉ sử dụng tập huấn luyện\n",
    ")\n",
    "\n",
    "val_data_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Chỉ sử dụng tập validation\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1 / 255.0)\n",
    "test_data_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data_generator.filepaths))\n",
    "print(len(val_data_generator.filepaths))\n",
    "print(len(test_data_generator.filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save log\n",
    "class TimeTrainCSVLogger(tf.keras.callbacks.CSVLogger):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "        super().on_epoch_begin(epoch, logs)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - self.epoch_start_time\n",
    "        logs['time_per_epoch'] = epoch_duration\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        print(f\"Epoch {epoch + 1} - Training Time: {epoch_duration:.2f} seconds\")\n",
    "        \n",
    "class TrainingTimeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.start_time = time.time()\n",
    "        super().on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        end_time = time.time()\n",
    "        duration = end_time - self.start_time\n",
    "        super().on_train_end(logs)\n",
    "        hours = duration // 3600\n",
    "        minutes = (duration - (hours * 3600)) // 60\n",
    "        seconds = duration - ((hours * 3600) + (minutes * 60))\n",
    "        \n",
    "        msg = f'Total Training Time: {int(hours)} hours, {int(minutes)} minutes, {seconds:.2f} seconds'\n",
    "        print(msg)\n",
    "\n",
    "        # Ghi tổng thời gian huấn luyện vào tệp CSV\n",
    "        with open('efficientNetV2M/log/train_logger5.csv', mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Total Training Time (seconds)'])\n",
    "            writer.writerow([duration])\n",
    "            writer.writerow(['Total Training Time (hours, minutes, seconds)'])\n",
    "            writer.writerow([hours, minutes, seconds])\n",
    "\n",
    "csv_logger = TimeTrainCSVLogger('efficientNetV2M/log/train_logger5.csv', append=True, separator='\\t')\n",
    "\n",
    "checkpoint_filepath = \"efficientNetV2M/checkpoint/cp5.ckpt\"\n",
    "directory_checkpoint = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    verbose=2,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer và loss function\n",
    "loss = CategoricalCrossentropy()\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics= ['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# Tính toán số bước cho tập train và tập validation\n",
    "steps_per_epoch = train_data_generator.samples // batch_size\n",
    "validation_steps = val_data_generator.samples // batch_size\n",
    "\n",
    "history = model.fit(train_data_generator,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          validation_steps= validation_steps, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=val_data_generator, \n",
    "          callbacks=[model_checkpoint_callback,csv_logger,TrainingTimeCallback()]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá mô hình trên tệp test\n",
    "test_loss, test_accuracy, test_recall, test_precision = model.evaluate(test_data_generator)\n",
    "\n",
    "print(f'Test_loss: {test_loss}')\n",
    "print(f'Test_accuracy: {test_accuracy}')\n",
    "print(f'Test_recall: {test_recall}')\n",
    "print(f'Test_precision: {test_precision}')\n",
    "\n",
    "with open('efficientNetV2M/Test_data_metrics5.txt', 'w') as file:\n",
    "    file.write(f'Test_loss: {test_loss}\\n')\n",
    "    file.write(f'Test_accuracy: {test_accuracy}\\n')\n",
    "    file.write(f'Test_recall: {test_recall}\\n')\n",
    "    file.write(f'Test_precision: {test_precision}\\n')\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save('efficientNetV2M/efficientNetV2M_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy thông tin về độ chính xác trên tập huấn luyện và tập validation\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của accuracy\n",
    "plt.plot(range(1, epochs + 1), train_accuracy, label='Training Accuracy')\n",
    "plt.plot(range(1, epochs + 1), val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2M/accuracy_vs_epochs_5.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Lấy thông tin về loss trên tập huấn luyện và tập validation\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của loss\n",
    "plt.plot(range(1, epochs + 1), train_loss, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2M/loss_vs_epochs_5.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'precision' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2M/precision_vs_epochs_5.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2M/recall_vs_epochs_5.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2M/recall_vs_epochs_5.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và lấy nhãn dự đoán\n",
    "y_pred = model.predict(test_data_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Lấy nhãn thật của tập kiểm tra\n",
    "y_true_indices = test_data_generator.classes\n",
    "\n",
    "# Lấy danh sách các lớp từ tên thư mục trong val_data_generator\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "\n",
    "# Sử dụng chỉ số thứ tự để lấy tên của các lớp từ danh sách tên lớp\n",
    "y_true_classes = [class_names[i] for i in y_true_indices]\n",
    "\n",
    "# Tính toán confusion matrix\n",
    "cm = confusion_matrix(y_true_indices, y_pred_labels)\n",
    "\n",
    "# Hiển thị confusion matrix bằng heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('efficientNetV2M/confusion_matrix_5.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Tính classification report\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "report = classification_report(y_true_indices, y_pred_labels, target_names=class_names, output_dict=True)\n",
    "\n",
    "# Tạo bảng classification report\n",
    "report_table = []\n",
    "for class_name, metrics in report.items():\n",
    "    if class_name in class_names:\n",
    "        row = [class_name, metrics['precision'], metrics['recall'], metrics['f1-score']]\n",
    "        report_table.append(row)\n",
    "\n",
    "headers = [\"Class\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "report_text = tabulate(report_table, headers, tablefmt=\"pretty\")\n",
    "# Lưu bảng classification report vào tệp văn bản\n",
    "with open('efficientNetV2M/classification_report_5.txt', 'w') as file:\n",
    "    file.write(report_text)\n",
    "\n",
    "# In bảng classification report ra màn hình\n",
    "print(report_text)\n",
    "\n",
    "# Chuyển đổi nhãn thành định dạng mã hóa one-hot\n",
    "y_test_binary = label_binarize(test_data_generator.labels, classes=range(len(class_names)))\n",
    "\n",
    "# Khởi tạo một từ điển trống để lưu FPR và TPR cho mỗi lớp\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "# Tạo một hình ảnh cho các đường ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Duyệt qua từng lớp\n",
    "for i in range(len(class_names)):\n",
    "    # Tính toán đường ROC và AUC cho lớp hiện tại\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binary[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Vẽ đường ROC cho lớp hiện tại\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve for {class_names[i]} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Cài đặt plot\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('efficientNetV2M/ROC_curve_5.png') # save before show. If not, it will save a blank image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNetV2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng mô hình\n",
    "num_classes = 4\n",
    "IMG_SIZE = 480\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2L(weights=None, include_top=True, classes=num_classes) \n",
    "predictions = base_model(inputs)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Đóng băng các lớp của mô hình base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save log\n",
    "class TimeTrainCSVLogger(tf.keras.callbacks.CSVLogger):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "        super().on_epoch_begin(epoch, logs)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - self.epoch_start_time\n",
    "        logs['time_per_epoch'] = epoch_duration\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        print(f\"Epoch {epoch + 1} - Training Time: {epoch_duration:.2f} seconds\")\n",
    "        \n",
    "class TrainingTimeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.start_time = time.time()\n",
    "        super().on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        end_time = time.time()\n",
    "        duration = end_time - self.start_time\n",
    "        super().on_train_end(logs)\n",
    "        hours = duration // 3600\n",
    "        minutes = (duration - (hours * 3600)) // 60\n",
    "        seconds = duration - ((hours * 3600) + (minutes * 60))\n",
    "        \n",
    "        msg = f'Total Training Time: {int(hours)} hours, {int(minutes)} minutes, {seconds:.2f} seconds'\n",
    "        print(msg)\n",
    "\n",
    "        # Ghi tổng thời gian huấn luyện vào tệp CSV\n",
    "        with open('efficientNetV2L/log/train_logger6.csv', mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Total Training Time (seconds)'])\n",
    "            writer.writerow([duration])\n",
    "            writer.writerow(['Total Training Time (hours, minutes, seconds)'])\n",
    "            writer.writerow([hours, minutes, seconds])\n",
    "\n",
    "csv_logger = TimeTrainCSVLogger('efficientNetV2L/log/train_logger6.csv', append=True, separator='\\t')\n",
    "\n",
    "checkpoint_filepath = \"efficientNetV2L/checkpoint/cp6.ckpt\"\n",
    "directory_checkpoint = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    verbose=2,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer và loss function\n",
    "loss = CategoricalCrossentropy()\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics= ['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# Tính toán số bước cho tập train và tập validation\n",
    "steps_per_epoch = train_data_generator.samples // batch_size\n",
    "validation_steps = val_data_generator.samples // batch_size\n",
    "\n",
    "history = model.fit(train_data_generator,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          validation_steps= validation_steps, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=val_data_generator, \n",
    "          callbacks=[model_checkpoint_callback,csv_logger,TrainingTimeCallback()]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá mô hình trên tệp test\n",
    "test_loss, test_accuracy, test_recall, test_precision = model.evaluate(test_data_generator)\n",
    "\n",
    "print(f'Test_loss: {test_loss}')\n",
    "print(f'Test_accuracy: {test_accuracy}')\n",
    "print(f'Test_recall: {test_recall}')\n",
    "print(f'Test_precision: {test_precision}')\n",
    "\n",
    "with open('efficientNetV2L/Test_data_metrics.txt', 'w') as file:\n",
    "    file.write(f'Test_loss: {test_loss}\\n')\n",
    "    file.write(f'Test_accuracy: {test_accuracy}\\n')\n",
    "    file.write(f'Test_recall: {test_recall}\\n')\n",
    "    file.write(f'Test_precision: {test_precision}\\n')\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save('efficientNetV2L/efficientNetV2L_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy thông tin về độ chính xác trên tập huấn luyện và tập validation\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của accuracy\n",
    "plt.plot(range(1, epochs + 1), train_accuracy, label='Training Accuracy')\n",
    "plt.plot(range(1, epochs + 1), val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2L/accuracy_vs_epochs_6.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Lấy thông tin về loss trên tập huấn luyện và tập validation\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của loss\n",
    "plt.plot(range(1, epochs + 1), train_loss, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2L/loss_vs_epochs_6.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'precision' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2L/precision_vs_epochs_6.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2L/recall_vs_epochs_6.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2L/recall_vs_epochs_6.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và lấy nhãn dự đoán\n",
    "y_pred = model.predict(test_data_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Lấy nhãn thật của tập kiểm tra\n",
    "y_true_indices = test_data_generator.classes\n",
    "\n",
    "# Lấy danh sách các lớp từ tên thư mục trong val_data_generator\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "\n",
    "# Sử dụng chỉ số thứ tự để lấy tên của các lớp từ danh sách tên lớp\n",
    "y_true_classes = [class_names[i] for i in y_true_indices]\n",
    "\n",
    "# Tính toán confusion matrix\n",
    "cm = confusion_matrix(y_true_indices, y_pred_labels)\n",
    "\n",
    "# Hiển thị confusion matrix bằng heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('efficientNetV2L/confusion_matrix_6.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Tính classification report\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "report = classification_report(y_true_indices, y_pred_labels, target_names=class_names, output_dict=True)\n",
    "\n",
    "# Tạo bảng classification report\n",
    "report_table = []\n",
    "for class_name, metrics in report.items():\n",
    "    if class_name in class_names:\n",
    "        row = [class_name, metrics['precision'], metrics['recall'], metrics['f1-score']]\n",
    "        report_table.append(row)\n",
    "\n",
    "headers = [\"Class\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "report_text = tabulate(report_table, headers, tablefmt=\"pretty\")\n",
    "# Lưu bảng classification report vào tệp văn bản\n",
    "with open('efficientNetV2L/classification_report_6.txt', 'w') as file:\n",
    "    file.write(report_text)\n",
    "\n",
    "# In bảng classification report ra màn hình\n",
    "print(report_text)\n",
    "\n",
    "# Chuyển đổi nhãn thành định dạng mã hóa one-hot\n",
    "y_test_binary = label_binarize(test_data_generator.labels, classes=range(len(class_names)))\n",
    "\n",
    "# Khởi tạo một từ điển trống để lưu FPR và TPR cho mỗi lớp\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "# Tạo một hình ảnh cho các đường ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Duyệt qua từng lớp\n",
    "for i in range(len(class_names)):\n",
    "    # Tính toán đường ROC và AUC cho lớp hiện tại\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binary[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Vẽ đường ROC cho lớp hiện tại\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve for {class_names[i]} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Cài đặt plot\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('efficientNetV2L/ROC_curve_6.png') # save before show. If not, it will save a blank image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNetV2B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng mô hình\n",
    "num_classes = 4\n",
    "IMG_SIZE = 240\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B1(weights=None, include_top=True, classes=num_classes) \n",
    "predictions = base_model(inputs)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Đóng băng các lớp của mô hình base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn đến thư mục chứa dữ liệu\n",
    "data_dir = 'Data_Cucur_augmented/train'\n",
    "test_dir = 'Data_Cucur_augmented/test'\n",
    "# Thiết lập các thông số\n",
    "validation_ratio = 0.1\n",
    "\n",
    "# Sử dụng ImageDataGenerator để tạo dữ liệu và áp dụng các biến đổi\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=validation_ratio,\n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Tạo generator cho tập train và tập validation\n",
    "train_data_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Chỉ sử dụng tập huấn luyện\n",
    ")\n",
    "\n",
    "val_data_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Chỉ sử dụng tập validation\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1 / 255.0)\n",
    "test_data_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data_generator.filepaths))\n",
    "print(len(val_data_generator.filepaths))\n",
    "print(len(test_data_generator.filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save log\n",
    "class TimeTrainCSVLogger(tf.keras.callbacks.CSVLogger):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "        super().on_epoch_begin(epoch, logs)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - self.epoch_start_time\n",
    "        logs['time_per_epoch'] = epoch_duration\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        print(f\"Epoch {epoch + 1} - Training Time: {epoch_duration:.2f} seconds\")\n",
    "        \n",
    "class TrainingTimeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.start_time = time.time()\n",
    "        super().on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        end_time = time.time()\n",
    "        duration = end_time - self.start_time\n",
    "        super().on_train_end(logs)\n",
    "        hours = duration // 3600\n",
    "        minutes = (duration - (hours * 3600)) // 60\n",
    "        seconds = duration - ((hours * 3600) + (minutes * 60))\n",
    "        \n",
    "        msg = f'Total Training Time: {int(hours)} hours, {int(minutes)} minutes, {seconds:.2f} seconds'\n",
    "        print(msg)\n",
    "\n",
    "        # Ghi tổng thời gian huấn luyện vào tệp CSV\n",
    "        with open('efficientNetV2B1/log/train_logger7.csv', mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Total Training Time (seconds)'])\n",
    "            writer.writerow([duration])\n",
    "            writer.writerow(['Total Training Time (hours, minutes, seconds)'])\n",
    "            writer.writerow([hours, minutes, seconds])\n",
    "\n",
    "csv_logger = TimeTrainCSVLogger('efficientNetV2B1/log/train_logger7.csv', append=True, separator='\\t')\n",
    "\n",
    "checkpoint_filepath = \"efficientNetV2B1/checkpoint/cp7.ckpt\"\n",
    "directory_checkpoint = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    verbose=2,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer và loss function\n",
    "loss = CategoricalCrossentropy()\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics= ['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# Tính toán số bước cho tập train và tập validation\n",
    "steps_per_epoch = train_data_generator.samples // batch_size\n",
    "validation_steps = val_data_generator.samples // batch_size\n",
    "\n",
    "history = model.fit(train_data_generator,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          validation_steps= validation_steps, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=val_data_generator, \n",
    "          callbacks=[model_checkpoint_callback,csv_logger,TrainingTimeCallback()]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá mô hình trên tệp test\n",
    "test_loss, test_accuracy, test_recall, test_precision = model.evaluate(test_data_generator)\n",
    "\n",
    "print(f'Test_loss: {test_loss}')\n",
    "print(f'Test_accuracy: {test_accuracy}')\n",
    "print(f'Test_recall: {test_recall}')\n",
    "print(f'Test_precision: {test_precision}')\n",
    "\n",
    "with open('efficientNetV2B1/Test_data_metrics.txt', 'w') as file:\n",
    "    file.write(f'Test_loss: {test_loss}\\n')\n",
    "    file.write(f'Test_accuracy: {test_accuracy}\\n')\n",
    "    file.write(f'Test_recall: {test_recall}\\n')\n",
    "    file.write(f'Test_precision: {test_precision}\\n')\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save('efficientNetV2B1/efficientNetV2B1_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy thông tin về độ chính xác trên tập huấn luyện và tập validation\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của accuracy\n",
    "plt.plot(range(1, epochs + 1), train_accuracy, label='Training Accuracy')\n",
    "plt.plot(range(1, epochs + 1), val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B1/accuracy_vs_epochs_7.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Lấy thông tin về loss trên tập huấn luyện và tập validation\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của loss\n",
    "plt.plot(range(1, epochs + 1), train_loss, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B1/loss_vs_epochs_7.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'precision' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B1/precision_vs_epochs_7.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B1/recall_vs_epochs_7.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B1/recall_vs_epochs_7.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và lấy nhãn dự đoán\n",
    "y_pred = model.predict(test_data_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Lấy nhãn thật của tập kiểm tra\n",
    "y_true_indices = test_data_generator.classes\n",
    "\n",
    "# Lấy danh sách các lớp từ tên thư mục trong val_data_generator\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "\n",
    "# Sử dụng chỉ số thứ tự để lấy tên của các lớp từ danh sách tên lớp\n",
    "y_true_classes = [class_names[i] for i in y_true_indices]\n",
    "\n",
    "# Tính toán confusion matrix\n",
    "cm = confusion_matrix(y_true_indices, y_pred_labels)\n",
    "\n",
    "# Hiển thị confusion matrix bằng heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('efficientNetV2B1/confusion_matrix_7.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Tính classification report\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "report = classification_report(y_true_indices, y_pred_labels, target_names=class_names, output_dict=True)\n",
    "\n",
    "# Tạo bảng classification report\n",
    "report_table = []\n",
    "for class_name, metrics in report.items():\n",
    "    if class_name in class_names:\n",
    "        row = [class_name, metrics['precision'], metrics['recall'], metrics['f1-score']]\n",
    "        report_table.append(row)\n",
    "\n",
    "headers = [\"Class\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "report_text = tabulate(report_table, headers, tablefmt=\"pretty\")\n",
    "# Lưu bảng classification report vào tệp văn bản\n",
    "with open('efficientNetV2B1/classification_report_7.txt', 'w') as file:\n",
    "    file.write(report_text)\n",
    "\n",
    "# In bảng classification report ra màn hình\n",
    "print(report_text)\n",
    "\n",
    "# Chuyển đổi nhãn thành định dạng mã hóa one-hot\n",
    "y_test_binary = label_binarize(test_data_generator.labels, classes=range(len(class_names)))\n",
    "\n",
    "# Khởi tạo một từ điển trống để lưu FPR và TPR cho mỗi lớp\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "# Tạo một hình ảnh cho các đường ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Duyệt qua từng lớp\n",
    "for i in range(len(class_names)):\n",
    "    # Tính toán đường ROC và AUC cho lớp hiện tại\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binary[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Vẽ đường ROC cho lớp hiện tại\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve for {class_names[i]} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Cài đặt plot\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('efficientNetV2B1/ROC_curve_7.png') # save before show. If not, it will save a blank image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNetV2B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng mô hình\n",
    "num_classes = 4\n",
    "IMG_SIZE = 260\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B2(weights=None, include_top=True, classes=num_classes) \n",
    "predictions = base_model(inputs)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Đóng băng các lớp của mô hình base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn đến thư mục chứa dữ liệu\n",
    "data_dir = 'Data_Cucur_augmented/train'\n",
    "test_dir = 'Data_Cucur_augmented/test'\n",
    "# Thiết lập các thông số\n",
    "validation_ratio = 0.1\n",
    "\n",
    "# Sử dụng ImageDataGenerator để tạo dữ liệu và áp dụng các biến đổi\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=validation_ratio,\n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Tạo generator cho tập train và tập validation\n",
    "train_data_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Chỉ sử dụng tập huấn luyện\n",
    ")\n",
    "\n",
    "val_data_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Chỉ sử dụng tập validation\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1 / 255.0)\n",
    "test_data_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data_generator.filepaths))\n",
    "print(len(val_data_generator.filepaths))\n",
    "print(len(test_data_generator.filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save log\n",
    "class TimeTrainCSVLogger(tf.keras.callbacks.CSVLogger):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "        super().on_epoch_begin(epoch, logs)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - self.epoch_start_time\n",
    "        logs['time_per_epoch'] = epoch_duration\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        print(f\"Epoch {epoch + 1} - Training Time: {epoch_duration:.2f} seconds\")\n",
    "        \n",
    "class TrainingTimeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.start_time = time.time()\n",
    "        super().on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        end_time = time.time()\n",
    "        duration = end_time - self.start_time\n",
    "        super().on_train_end(logs)\n",
    "        hours = duration // 3600\n",
    "        minutes = (duration - (hours * 3600)) // 60\n",
    "        seconds = duration - ((hours * 3600) + (minutes * 60))\n",
    "        \n",
    "        msg = f'Total Training Time: {int(hours)} hours, {int(minutes)} minutes, {seconds:.2f} seconds'\n",
    "        print(msg)\n",
    "\n",
    "        # Ghi tổng thời gian huấn luyện vào tệp CSV\n",
    "        with open('efficientNetV2B2/log/train_logger8.csv', mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Total Training Time (seconds)'])\n",
    "            writer.writerow([duration])\n",
    "            writer.writerow(['Total Training Time (hours, minutes, seconds)'])\n",
    "            writer.writerow([hours, minutes, seconds])\n",
    "\n",
    "csv_logger = TimeTrainCSVLogger('efficientNetV2B2/log/train_logger8.csv', append=True, separator='\\t')\n",
    "\n",
    "checkpoint_filepath = \"efficientNetV2B2/checkpoint/cp8.ckpt\"\n",
    "directory_checkpoint = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    verbose=2,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer và loss function\n",
    "loss = CategoricalCrossentropy()\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics= ['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# Tính toán số bước cho tập train và tập validation\n",
    "steps_per_epoch = train_data_generator.samples // batch_size\n",
    "validation_steps = val_data_generator.samples // batch_size\n",
    "\n",
    "history = model.fit(train_data_generator,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          validation_steps= validation_steps, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=val_data_generator, \n",
    "          callbacks=[model_checkpoint_callback,csv_logger,TrainingTimeCallback()]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá mô hình trên tệp test\n",
    "test_loss, test_accuracy, test_recall, test_precision = model.evaluate(test_data_generator)\n",
    "\n",
    "print(f'Test_loss: {test_loss}')\n",
    "print(f'Test_accuracy: {test_accuracy}')\n",
    "print(f'Test_recall: {test_recall}')\n",
    "print(f'Test_precision: {test_precision}')\n",
    "\n",
    "with open('efficientNetV2B2/Test_data_metrics.txt', 'w') as file:\n",
    "    file.write(f'Test_loss: {test_loss}\\n')\n",
    "    file.write(f'Test_accuracy: {test_accuracy}\\n')\n",
    "    file.write(f'Test_recall: {test_recall}\\n')\n",
    "    file.write(f'Test_precision: {test_precision}\\n')\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save('efficientNetV2B2/efficientNetV2B2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy thông tin về độ chính xác trên tập huấn luyện và tập validation\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của accuracy\n",
    "plt.plot(range(1, epochs + 1), train_accuracy, label='Training Accuracy')\n",
    "plt.plot(range(1, epochs + 1), val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B2/accuracy_vs_epochs_8.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Lấy thông tin về loss trên tập huấn luyện và tập validation\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của loss\n",
    "plt.plot(range(1, epochs + 1), train_loss, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B2/loss_vs_epochs_8.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'precision' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B2/precision_vs_epochs_8.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B2/recall_vs_epochs_8.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B2/recall_vs_epochs_8.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và lấy nhãn dự đoán\n",
    "y_pred = model.predict(test_data_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Lấy nhãn thật của tập kiểm tra\n",
    "y_true_indices = test_data_generator.classes\n",
    "\n",
    "# Lấy danh sách các lớp từ tên thư mục trong val_data_generator\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "\n",
    "# Sử dụng chỉ số thứ tự để lấy tên của các lớp từ danh sách tên lớp\n",
    "y_true_classes = [class_names[i] for i in y_true_indices]\n",
    "\n",
    "# Tính toán confusion matrix\n",
    "cm = confusion_matrix(y_true_indices, y_pred_labels)\n",
    "\n",
    "# Hiển thị confusion matrix bằng heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('efficientNetV2B2/confusion_matrix_8.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Tính classification report\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "report = classification_report(y_true_indices, y_pred_labels, target_names=class_names, output_dict=True)\n",
    "\n",
    "# Tạo bảng classification report\n",
    "report_table = []\n",
    "for class_name, metrics in report.items():\n",
    "    if class_name in class_names:\n",
    "        row = [class_name, metrics['precision'], metrics['recall'], metrics['f1-score']]\n",
    "        report_table.append(row)\n",
    "\n",
    "headers = [\"Class\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "report_text = tabulate(report_table, headers, tablefmt=\"pretty\")\n",
    "# Lưu bảng classification report vào tệp văn bản\n",
    "with open('efficientNetV2B2/classification_report_8.txt', 'w') as file:\n",
    "    file.write(report_text)\n",
    "\n",
    "# In bảng classification report ra màn hình\n",
    "print(report_text)\n",
    "\n",
    "# Chuyển đổi nhãn thành định dạng mã hóa one-hot\n",
    "y_test_binary = label_binarize(test_data_generator.labels, classes=range(len(class_names)))\n",
    "\n",
    "# Khởi tạo một từ điển trống để lưu FPR và TPR cho mỗi lớp\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "# Tạo một hình ảnh cho các đường ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Duyệt qua từng lớp\n",
    "for i in range(len(class_names)):\n",
    "    # Tính toán đường ROC và AUC cho lớp hiện tại\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binary[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Vẽ đường ROC cho lớp hiện tại\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve for {class_names[i]} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Cài đặt plot\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('efficientNetV2B2/ROC_curve_8.png') # save before show. If not, it will save a blank image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNetV2B3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng mô hình\n",
    "num_classes = 4\n",
    "IMG_SIZE = 300\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B3(weights=None, include_top=True, classes=num_classes) \n",
    "predictions = base_model(inputs)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Đóng băng các lớp của mô hình base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn đến thư mục chứa dữ liệu\n",
    "data_dir = 'Data_Cucur_augmented/train'\n",
    "test_dir = 'Data_Cucur_augmented/test'\n",
    "# Thiết lập các thông số\n",
    "validation_ratio = 0.1\n",
    "\n",
    "# Sử dụng ImageDataGenerator để tạo dữ liệu và áp dụng các biến đổi\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=validation_ratio,\n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Tạo generator cho tập train và tập validation\n",
    "train_data_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Chỉ sử dụng tập huấn luyện\n",
    ")\n",
    "\n",
    "val_data_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Chỉ sử dụng tập validation\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1 / 255.0)\n",
    "test_data_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data_generator.filepaths))\n",
    "print(len(val_data_generator.filepaths))\n",
    "print(len(test_data_generator.filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save log\n",
    "class TimeTrainCSVLogger(tf.keras.callbacks.CSVLogger):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "        super().on_epoch_begin(epoch, logs)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - self.epoch_start_time\n",
    "        logs['time_per_epoch'] = epoch_duration\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        print(f\"Epoch {epoch + 1} - Training Time: {epoch_duration:.2f} seconds\")\n",
    "        \n",
    "class TrainingTimeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.start_time = time.time()\n",
    "        super().on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        end_time = time.time()\n",
    "        duration = end_time - self.start_time\n",
    "        super().on_train_end(logs)\n",
    "        hours = duration // 3600\n",
    "        minutes = (duration - (hours * 3600)) // 60\n",
    "        seconds = duration - ((hours * 3600) + (minutes * 60))\n",
    "        \n",
    "        msg = f'Total Training Time: {int(hours)} hours, {int(minutes)} minutes, {seconds:.2f} seconds'\n",
    "        print(msg)\n",
    "\n",
    "        # Ghi tổng thời gian huấn luyện vào tệp CSV\n",
    "        with open('efficientNetV2B3/log/train_logger9.csv', mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Total Training Time (seconds)'])\n",
    "            writer.writerow([duration])\n",
    "            writer.writerow(['Total Training Time (hours, minutes, seconds)'])\n",
    "            writer.writerow([hours, minutes, seconds])\n",
    "\n",
    "csv_logger = TimeTrainCSVLogger('efficientNetV2B3/log/train_logger9.csv', append=True, separator='\\t')\n",
    "\n",
    "checkpoint_filepath = \"efficientNetV2B3/checkpoint/cp9.ckpt\"\n",
    "directory_checkpoint = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    verbose=2,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer và loss function\n",
    "loss = CategoricalCrossentropy()\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics= ['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# Tính toán số bước cho tập train và tập validation\n",
    "steps_per_epoch = train_data_generator.samples // batch_size\n",
    "validation_steps = val_data_generator.samples // batch_size\n",
    "\n",
    "history = model.fit(train_data_generator,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          validation_steps= validation_steps, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=val_data_generator, \n",
    "          callbacks=[model_checkpoint_callback,csv_logger,TrainingTimeCallback()]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá mô hình trên tệp test\n",
    "test_loss, test_accuracy, test_recall, test_precision = model.evaluate(test_data_generator)\n",
    "\n",
    "print(f'Test_loss: {test_loss}')\n",
    "print(f'Test_accuracy: {test_accuracy}')\n",
    "print(f'Test_recall: {test_recall}')\n",
    "print(f'Test_precision: {test_precision}')\n",
    "\n",
    "with open('efficientNetV2B3/Test_data_metrics.txt', 'w') as file:\n",
    "    file.write(f'Test_loss: {test_loss}\\n')\n",
    "    file.write(f'Test_accuracy: {test_accuracy}\\n')\n",
    "    file.write(f'Test_recall: {test_recall}\\n')\n",
    "    file.write(f'Test_precision: {test_precision}\\n')\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save('efficientNetV2B3/efficientNetV2B3_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy thông tin về độ chính xác trên tập huấn luyện và tập validation\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của accuracy\n",
    "plt.plot(range(1, epochs + 1), train_accuracy, label='Training Accuracy')\n",
    "plt.plot(range(1, epochs + 1), val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B3/accuracy_vs_epochs_9.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Lấy thông tin về loss trên tập huấn luyện và tập validation\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của loss\n",
    "plt.plot(range(1, epochs + 1), train_loss, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B3/loss_vs_epochs_9.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'precision' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B3/precision_vs_epochs_9.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B3/recall_vs_epochs_9.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2B3/recall_vs_epochs_9.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và lấy nhãn dự đoán\n",
    "y_pred = model.predict(test_data_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Lấy nhãn thật của tập kiểm tra\n",
    "y_true_indices = test_data_generator.classes\n",
    "\n",
    "# Lấy danh sách các lớp từ tên thư mục trong val_data_generator\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "\n",
    "# Sử dụng chỉ số thứ tự để lấy tên của các lớp từ danh sách tên lớp\n",
    "y_true_classes = [class_names[i] for i in y_true_indices]\n",
    "\n",
    "# Tính toán confusion matrix\n",
    "cm = confusion_matrix(y_true_indices, y_pred_labels)\n",
    "\n",
    "# Hiển thị confusion matrix bằng heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('efficientNetV2B3/confusion_matrix_9.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Tính classification report\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "report = classification_report(y_true_indices, y_pred_labels, target_names=class_names, output_dict=True)\n",
    "\n",
    "# Tạo bảng classification report\n",
    "report_table = []\n",
    "for class_name, metrics in report.items():\n",
    "    if class_name in class_names:\n",
    "        row = [class_name, metrics['precision'], metrics['recall'], metrics['f1-score']]\n",
    "        report_table.append(row)\n",
    "\n",
    "headers = [\"Class\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "report_text = tabulate(report_table, headers, tablefmt=\"pretty\")\n",
    "# Lưu bảng classification report vào tệp văn bản\n",
    "with open('efficientNetV2B3/classification_report_9.txt', 'w') as file:\n",
    "    file.write(report_text)\n",
    "\n",
    "# In bảng classification report ra màn hình\n",
    "print(report_text)\n",
    "\n",
    "# Chuyển đổi nhãn thành định dạng mã hóa one-hot\n",
    "y_test_binary = label_binarize(test_data_generator.labels, classes=range(len(class_names)))\n",
    "\n",
    "# Khởi tạo một từ điển trống để lưu FPR và TPR cho mỗi lớp\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "# Tạo một hình ảnh cho các đường ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Duyệt qua từng lớp\n",
    "for i in range(len(class_names)):\n",
    "    # Tính toán đường ROC và AUC cho lớp hiện tại\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binary[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Vẽ đường ROC cho lớp hiện tại\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve for {class_names[i]} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Cài đặt plot\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('efficientNetV2B3/ROC_curve_9.png') # save before show. If not, it will save a blank image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNetV2S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng mô hình\n",
    "num_classes = 4\n",
    "IMG_SIZE = 384\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2S(weights=None, include_top=True, classes=num_classes) \n",
    "predictions = base_model(inputs)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Đóng băng các lớp của mô hình base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn đến thư mục chứa dữ liệu\n",
    "data_dir = 'Data_Cucur_augmented/train'\n",
    "test_dir = 'Data_Cucur_augmented/test'\n",
    "# Thiết lập các thông số\n",
    "validation_ratio = 0.1\n",
    "\n",
    "# Sử dụng ImageDataGenerator để tạo dữ liệu và áp dụng các biến đổi\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=validation_ratio,\n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Tạo generator cho tập train và tập validation\n",
    "train_data_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Chỉ sử dụng tập huấn luyện\n",
    ")\n",
    "\n",
    "val_data_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Chỉ sử dụng tập validation\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1 / 255.0)\n",
    "test_data_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data_generator.filepaths))\n",
    "print(len(val_data_generator.filepaths))\n",
    "print(len(test_data_generator.filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save log\n",
    "class TimeTrainCSVLogger(tf.keras.callbacks.CSVLogger):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "        super().on_epoch_begin(epoch, logs)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - self.epoch_start_time\n",
    "        logs['time_per_epoch'] = epoch_duration\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        print(f\"Epoch {epoch + 1} - Training Time: {epoch_duration:.2f} seconds\")\n",
    "        \n",
    "class TrainingTimeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.start_time = time.time()\n",
    "        super().on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        end_time = time.time()\n",
    "        duration = end_time - self.start_time\n",
    "        super().on_train_end(logs)\n",
    "        hours = duration // 3600\n",
    "        minutes = (duration - (hours * 3600)) // 60\n",
    "        seconds = duration - ((hours * 3600) + (minutes * 60))\n",
    "        \n",
    "        msg = f'Total Training Time: {int(hours)} hours, {int(minutes)} minutes, {seconds:.2f} seconds'\n",
    "        print(msg)\n",
    "\n",
    "        # Ghi tổng thời gian huấn luyện vào tệp CSV\n",
    "        with open('efficientNetV2S/log/train_logger10.csv', mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Total Training Time (seconds)'])\n",
    "            writer.writerow([duration])\n",
    "            writer.writerow(['Total Training Time (hours, minutes, seconds)'])\n",
    "            writer.writerow([hours, minutes, seconds])\n",
    "\n",
    "csv_logger = TimeTrainCSVLogger('efficientNetV2S/log/train_logger10.csv', append=True, separator='\\t')\n",
    "\n",
    "checkpoint_filepath = \"efficientNetV2S/checkpoint/cp10.ckpt\"\n",
    "directory_checkpoint = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    verbose=2,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer và loss function\n",
    "loss = CategoricalCrossentropy()\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics= ['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# Tính toán số bước cho tập train và tập validation\n",
    "steps_per_epoch = train_data_generator.samples // batch_size\n",
    "validation_steps = val_data_generator.samples // batch_size\n",
    "\n",
    "history = model.fit(train_data_generator,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          validation_steps= validation_steps, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=val_data_generator, \n",
    "          callbacks=[model_checkpoint_callback,csv_logger,TrainingTimeCallback()]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá mô hình trên tệp test\n",
    "test_loss, test_accuracy, test_recall, test_precision = model.evaluate(test_data_generator)\n",
    "\n",
    "print(f'Test_loss: {test_loss}')\n",
    "print(f'Test_accuracy: {test_accuracy}')\n",
    "print(f'Test_recall: {test_recall}')\n",
    "print(f'Test_precision: {test_precision}')\n",
    "\n",
    "with open('efficientNetV2S/Test_data_metrics.txt', 'w') as file:\n",
    "    file.write(f'Test_loss: {test_loss}\\n')\n",
    "    file.write(f'Test_accuracy: {test_accuracy}\\n')\n",
    "    file.write(f'Test_recall: {test_recall}\\n')\n",
    "    file.write(f'Test_precision: {test_precision}\\n')\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save('efficientNetV2S/efficientNetV2S_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy thông tin về độ chính xác trên tập huấn luyện và tập validation\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của accuracy\n",
    "plt.plot(range(1, epochs + 1), train_accuracy, label='Training Accuracy')\n",
    "plt.plot(range(1, epochs + 1), val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2S/accuracy_vs_epochs_10.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Lấy thông tin về loss trên tập huấn luyện và tập validation\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của loss\n",
    "plt.plot(range(1, epochs + 1), train_loss, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2S/loss_vs_epochs_10.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'precision' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2S/precision_vs_epochs_10.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2S/recall_vs_epochs_10.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetV2S/recall_vs_epochs_10.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và lấy nhãn dự đoán\n",
    "y_pred = model.predict(test_data_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Lấy nhãn thật của tập kiểm tra\n",
    "y_true_indices = test_data_generator.classes\n",
    "\n",
    "# Lấy danh sách các lớp từ tên thư mục trong val_data_generator\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "\n",
    "# Sử dụng chỉ số thứ tự để lấy tên của các lớp từ danh sách tên lớp\n",
    "y_true_classes = [class_names[i] for i in y_true_indices]\n",
    "\n",
    "# Tính toán confusion matrix\n",
    "cm = confusion_matrix(y_true_indices, y_pred_labels)\n",
    "\n",
    "# Hiển thị confusion matrix bằng heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('efficientNetV2S/confusion_matrix_10.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Tính classification report\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "report = classification_report(y_true_indices, y_pred_labels, target_names=class_names, output_dict=True)\n",
    "\n",
    "# Tạo bảng classification report\n",
    "report_table = []\n",
    "for class_name, metrics in report.items():\n",
    "    if class_name in class_names:\n",
    "        row = [class_name, metrics['precision'], metrics['recall'], metrics['f1-score']]\n",
    "        report_table.append(row)\n",
    "\n",
    "headers = [\"Class\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "report_text = tabulate(report_table, headers, tablefmt=\"pretty\")\n",
    "# Lưu bảng classification report vào tệp văn bản\n",
    "with open('efficientNetV2S/classification_report_10.txt', 'w') as file:\n",
    "    file.write(report_text)\n",
    "\n",
    "# In bảng classification report ra màn hình\n",
    "print(report_text)\n",
    "\n",
    "# Chuyển đổi nhãn thành định dạng mã hóa one-hot\n",
    "y_test_binary = label_binarize(test_data_generator.labels, classes=range(len(class_names)))\n",
    "\n",
    "# Khởi tạo một từ điển trống để lưu FPR và TPR cho mỗi lớp\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "# Tạo một hình ảnh cho các đường ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Duyệt qua từng lớp\n",
    "for i in range(len(class_names)):\n",
    "    # Tính toán đường ROC và AUC cho lớp hiện tại\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binary[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Vẽ đường ROC cho lớp hiện tại\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve for {class_names[i]} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Cài đặt plot\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('efficientNetV2S/ROC_curve_10.png') # save before show. If not, it will save a blank image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNetB4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng mô hình\n",
    "num_classes = 4\n",
    "IMG_SIZE = 380\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model = tf.keras.applications.efficientnet.EfficientNetB4(weights=None, include_top=True, classes=num_classes) \n",
    "predictions = base_model(inputs)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Đóng băng các lớp của mô hình base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn đến thư mục chứa dữ liệu\n",
    "data_dir = 'Data_Cucur_augmented/train'\n",
    "test_dir = 'Data_Cucur_augmented/test'\n",
    "# Thiết lập các thông số\n",
    "validation_ratio = 0.1\n",
    "\n",
    "# Sử dụng ImageDataGenerator để tạo dữ liệu và áp dụng các biến đổi\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=validation_ratio,\n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Tạo generator cho tập train và tập validation\n",
    "train_data_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Chỉ sử dụng tập huấn luyện\n",
    ")\n",
    "\n",
    "val_data_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Chỉ sử dụng tập validation\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1 / 255.0)\n",
    "test_data_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data_generator.filepaths))\n",
    "print(len(val_data_generator.filepaths))\n",
    "print(len(test_data_generator.filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save log\n",
    "class TimeTrainCSVLogger(tf.keras.callbacks.CSVLogger):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "        super().on_epoch_begin(epoch, logs)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - self.epoch_start_time\n",
    "        logs['time_per_epoch'] = epoch_duration\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        print(f\"Epoch {epoch + 1} - Training Time: {epoch_duration:.2f} seconds\")\n",
    "        \n",
    "class TrainingTimeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.start_time = time.time()\n",
    "        super().on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        end_time = time.time()\n",
    "        duration = end_time - self.start_time\n",
    "        super().on_train_end(logs)\n",
    "        hours = duration // 3600\n",
    "        minutes = (duration - (hours * 3600)) // 60\n",
    "        seconds = duration - ((hours * 3600) + (minutes * 60))\n",
    "        \n",
    "        msg = f'Total Training Time: {int(hours)} hours, {int(minutes)} minutes, {seconds:.2f} seconds'\n",
    "        print(msg)\n",
    "\n",
    "        # Ghi tổng thời gian huấn luyện vào tệp CSV\n",
    "        with open('efficientNetB4/log/train_logger11.csv', mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Total Training Time (seconds)'])\n",
    "            writer.writerow([duration])\n",
    "            writer.writerow(['Total Training Time (hours, minutes, seconds)'])\n",
    "            writer.writerow([hours, minutes, seconds])\n",
    "\n",
    "csv_logger = TimeTrainCSVLogger('efficientNetB4/log/train_logger11.csv', append=True, separator='\\t')\n",
    "\n",
    "checkpoint_filepath = \"efficientNetB4/checkpoint/cp11.ckpt\"\n",
    "directory_checkpoint = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    verbose=2,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer và loss function\n",
    "loss = CategoricalCrossentropy()\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics= ['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# Tính toán số bước cho tập train và tập validation\n",
    "steps_per_epoch = train_data_generator.samples // batch_size\n",
    "validation_steps = val_data_generator.samples // batch_size\n",
    "\n",
    "history = model.fit(train_data_generator,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          validation_steps= validation_steps, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=val_data_generator, \n",
    "          callbacks=[model_checkpoint_callback,csv_logger,TrainingTimeCallback()]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá mô hình trên tệp test\n",
    "test_loss, test_accuracy, test_recall, test_precision = model.evaluate(test_data_generator)\n",
    "\n",
    "print(f'Test_loss: {test_loss}')\n",
    "print(f'Test_accuracy: {test_accuracy}')\n",
    "print(f'Test_recall: {test_recall}')\n",
    "print(f'Test_precision: {test_precision}')\n",
    "\n",
    "with open('efficientNetB4/Test_data_metrics11.txt', 'w') as file:\n",
    "    file.write(f'Test_loss: {test_loss}\\n')\n",
    "    file.write(f'Test_accuracy: {test_accuracy}\\n')\n",
    "    file.write(f'Test_recall: {test_recall}\\n')\n",
    "    file.write(f'Test_precision: {test_precision}\\n')\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save('efficientNetB4/efficientNetB4_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy thông tin về độ chính xác trên tập huấn luyện và tập validation\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của accuracy\n",
    "plt.plot(range(1, epochs + 1), train_accuracy, label='Training Accuracy')\n",
    "plt.plot(range(1, epochs + 1), val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetB4/accuracy_vs_epochs_11.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Lấy thông tin về loss trên tập huấn luyện và tập validation\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của loss\n",
    "plt.plot(range(1, epochs + 1), train_loss, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetB4/loss_vs_epochs_11.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'precision' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetB4/precision_vs_epochs_11.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetB4/recall_vs_epochs_11.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetB4/recall_vs_epochs_11.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và lấy nhãn dự đoán\n",
    "y_pred = model.predict(test_data_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Lấy nhãn thật của tập kiểm tra\n",
    "y_true_indices = test_data_generator.classes\n",
    "\n",
    "# Lấy danh sách các lớp từ tên thư mục trong val_data_generator\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "\n",
    "# Sử dụng chỉ số thứ tự để lấy tên của các lớp từ danh sách tên lớp\n",
    "y_true_classes = [class_names[i] for i in y_true_indices]\n",
    "\n",
    "# Tính toán confusion matrix\n",
    "cm = confusion_matrix(y_true_indices, y_pred_labels)\n",
    "\n",
    "# Hiển thị confusion matrix bằng heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('efficientNetB4/confusion_matrix_11.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Tính classification report\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "report = classification_report(y_true_indices, y_pred_labels, target_names=class_names, output_dict=True)\n",
    "\n",
    "# Tạo bảng classification report\n",
    "report_table = []\n",
    "for class_name, metrics in report.items():\n",
    "    if class_name in class_names:\n",
    "        row = [class_name, metrics['precision'], metrics['recall'], metrics['f1-score']]\n",
    "        report_table.append(row)\n",
    "\n",
    "headers = [\"Class\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "report_text = tabulate(report_table, headers, tablefmt=\"pretty\")\n",
    "# Lưu bảng classification report vào tệp văn bản\n",
    "with open('efficientNetB4/classification_report_11.txt', 'w') as file:\n",
    "    file.write(report_text)\n",
    "\n",
    "# In bảng classification report ra màn hình\n",
    "print(report_text)\n",
    "\n",
    "# Chuyển đổi nhãn thành định dạng mã hóa one-hot\n",
    "y_test_binary = label_binarize(test_data_generator.labels, classes=range(len(class_names)))\n",
    "\n",
    "# Khởi tạo một từ điển trống để lưu FPR và TPR cho mỗi lớp\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "# Tạo một hình ảnh cho các đường ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Duyệt qua từng lớp\n",
    "for i in range(len(class_names)):\n",
    "    # Tính toán đường ROC và AUC cho lớp hiện tại\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binary[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Vẽ đường ROC cho lớp hiện tại\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve for {class_names[i]} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Cài đặt plot\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('efficientNetB4/ROC_curve_11.png') # save before show. If not, it will save a blank image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNetB5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng mô hình\n",
    "num_classes = 4\n",
    "IMG_SIZE = 456\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model = tf.keras.applications.efficientnet.EfficientNetB5(weights=None, include_top=True, classes=num_classes) \n",
    "predictions = base_model(inputs)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Đóng băng các lớp của mô hình base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn đến thư mục chứa dữ liệu\n",
    "data_dir = 'Data_Cucur_augmented/train'\n",
    "test_dir = 'Data_Cucur_augmented/test'\n",
    "# Thiết lập các thông số\n",
    "validation_ratio = 0.1\n",
    "\n",
    "# Sử dụng ImageDataGenerator để tạo dữ liệu và áp dụng các biến đổi\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=validation_ratio,\n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Tạo generator cho tập train và tập validation\n",
    "train_data_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Chỉ sử dụng tập huấn luyện\n",
    ")\n",
    "\n",
    "val_data_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Chỉ sử dụng tập validation\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1 / 255.0)\n",
    "test_data_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data_generator.filepaths))\n",
    "print(len(val_data_generator.filepaths))\n",
    "print(len(test_data_generator.filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save log\n",
    "class TimeTrainCSVLogger(tf.keras.callbacks.CSVLogger):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "        super().on_epoch_begin(epoch, logs)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - self.epoch_start_time\n",
    "        logs['time_per_epoch'] = epoch_duration\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        print(f\"Epoch {epoch + 1} - Training Time: {epoch_duration:.2f} seconds\")\n",
    "        \n",
    "class TrainingTimeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.start_time = time.time()\n",
    "        super().on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        end_time = time.time()\n",
    "        duration = end_time - self.start_time\n",
    "        super().on_train_end(logs)\n",
    "        hours = duration // 3600\n",
    "        minutes = (duration - (hours * 3600)) // 60\n",
    "        seconds = duration - ((hours * 3600) + (minutes * 60))\n",
    "        \n",
    "        msg = f'Total Training Time: {int(hours)} hours, {int(minutes)} minutes, {seconds:.2f} seconds'\n",
    "        print(msg)\n",
    "\n",
    "        # Ghi tổng thời gian huấn luyện vào tệp CSV\n",
    "        with open('efficientNetB5/log/train_logger12.csv', mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Total Training Time (seconds)'])\n",
    "            writer.writerow([duration])\n",
    "            writer.writerow(['Total Training Time (hours, minutes, seconds)'])\n",
    "            writer.writerow([hours, minutes, seconds])\n",
    "\n",
    "csv_logger = TimeTrainCSVLogger('efficientNetB5/log/train_logger12.csv', append=True, separator='\\t')\n",
    "\n",
    "checkpoint_filepath = \"efficientNetB5/checkpoint/cp12.ckpt\"\n",
    "directory_checkpoint = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    verbose=2,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer và loss function\n",
    "loss = CategoricalCrossentropy()\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics= ['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# Tính toán số bước cho tập train và tập validation\n",
    "steps_per_epoch = train_data_generator.samples // batch_size\n",
    "validation_steps = val_data_generator.samples // batch_size\n",
    "\n",
    "history = model.fit(train_data_generator,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          validation_steps= validation_steps, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=val_data_generator, \n",
    "          callbacks=[model_checkpoint_callback,csv_logger,TrainingTimeCallback()]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá mô hình trên tệp test\n",
    "test_loss, test_accuracy, test_recall, test_precision = model.evaluate(test_data_generator)\n",
    "\n",
    "print(f'Test_loss: {test_loss}')\n",
    "print(f'Test_accuracy: {test_accuracy}')\n",
    "print(f'Test_recall: {test_recall}')\n",
    "print(f'Test_precision: {test_precision}')\n",
    "\n",
    "with open('efficientNetB5/Test_data_metrics.txt', 'w') as file:\n",
    "    file.write(f'Test_loss: {test_loss}\\n')\n",
    "    file.write(f'Test_accuracy: {test_accuracy}\\n')\n",
    "    file.write(f'Test_recall: {test_recall}\\n')\n",
    "    file.write(f'Test_precision: {test_precision}\\n')\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save('efficientNetB5/efficientNetB5_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy thông tin về độ chính xác trên tập huấn luyện và tập validation\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của accuracy\n",
    "plt.plot(range(1, epochs + 1), train_accuracy, label='Training Accuracy')\n",
    "plt.plot(range(1, epochs + 1), val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetB5/accuracy_vs_epochs_12.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Lấy thông tin về loss trên tập huấn luyện và tập validation\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của loss\n",
    "plt.plot(range(1, epochs + 1), train_loss, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetB5/loss_vs_epochs_12.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'precision' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetB5/precision_vs_epochs_12.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetB5/recall_vs_epochs_12.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('efficientNetB5/recall_vs_epochs_12.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và lấy nhãn dự đoán\n",
    "y_pred = model.predict(test_data_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Lấy nhãn thật của tập kiểm tra\n",
    "y_true_indices = test_data_generator.classes\n",
    "\n",
    "# Lấy danh sách các lớp từ tên thư mục trong val_data_generator\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "\n",
    "# Sử dụng chỉ số thứ tự để lấy tên của các lớp từ danh sách tên lớp\n",
    "y_true_classes = [class_names[i] for i in y_true_indices]\n",
    "\n",
    "# Tính toán confusion matrix\n",
    "cm = confusion_matrix(y_true_indices, y_pred_labels)\n",
    "\n",
    "# Hiển thị confusion matrix bằng heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('efficientNetB5/confusion_matrix_12.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Tính classification report\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "report = classification_report(y_true_indices, y_pred_labels, target_names=class_names, output_dict=True)\n",
    "\n",
    "# Tạo bảng classification report\n",
    "report_table = []\n",
    "for class_name, metrics in report.items():\n",
    "    if class_name in class_names:\n",
    "        row = [class_name, metrics['precision'], metrics['recall'], metrics['f1-score']]\n",
    "        report_table.append(row)\n",
    "\n",
    "headers = [\"Class\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "report_text = tabulate(report_table, headers, tablefmt=\"pretty\")\n",
    "# Lưu bảng classification report vào tệp văn bản\n",
    "with open('efficientNetB5/classification_report_12.txt', 'w') as file:\n",
    "    file.write(report_text)\n",
    "\n",
    "# In bảng classification report ra màn hình\n",
    "print(report_text)\n",
    "\n",
    "# Chuyển đổi nhãn thành định dạng mã hóa one-hot\n",
    "y_test_binary = label_binarize(test_data_generator.labels, classes=range(len(class_names)))\n",
    "\n",
    "# Khởi tạo một từ điển trống để lưu FPR và TPR cho mỗi lớp\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "# Tạo một hình ảnh cho các đường ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Duyệt qua từng lớp\n",
    "for i in range(len(class_names)):\n",
    "    # Tính toán đường ROC và AUC cho lớp hiện tại\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binary[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Vẽ đường ROC cho lớp hiện tại\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve for {class_names[i]} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Cài đặt plot\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('efficientNetB5/ROC_curve_12.png') # save before show. If not, it will save a blank image\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
